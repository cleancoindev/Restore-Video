function final = fixVideo(path, prefix, first, last, digits, suffix)

close all;

original = im2double(load_sequence(path, prefix, first, last, digits, suffix));
edited = im2double(load_sequence(path, prefix, first, last, digits, suffix));

vertical = size(edited, 1);
horizontal = size(edited, 2);
numberOfFrames = size(edited, 3);

cuts = detectSceneCuts(path, prefix, first, last, digits, suffix, vertical, horizontal);

corrected = applyCorrections(edited, cuts, first, last, vertical, horizontal, numberOfFrames);

final = overlayText(corrected, cuts);

implay([original, final]);

save_sequence(final, path, strcat('restored_',  prefix), first, digits);

end



% =========================================================================
% Detect scene cuts
% =========================================================================
% Loop through frames, compare each to the next. If intensity > pixel
% threshold, consider pixel as one which changed significantly and keep a
% count of these. Compare result to scene change threshold to determine if
% enough pixels changed to consider it a scene change.
function cuts = detectSceneCuts(path, prefix, first, last, digits, suffix, vertical, horizontal)

% Play with these for different results
pixelThreshold = 0.1;
sceneChangeThreshold = 0.75;

% Initialise video output and change counter
cutArray = [];
changes = 0;

for count = (first : (last - 1))

	unedited = im2double(load_sequence(path, prefix, count, count + 1, digits, suffix));
    changedPixels = 0;
    
    % Loop over each pixel per column, treating image as matrix
    for i = 1 : vertical
        for j = 1 : horizontal
            imageDiff = unedited(i, j, 1) - unedited(i, j, 2);
            % Compare current pixel to threshold
            if (pixelThreshold < abs(imageDiff))
                changedPixels = changedPixels + 1;
            end
        end
    end
    
    % Denominator is total number of pixels
	proportionChanged = changedPixels / (vertical * horizontal);

	if (sceneChangeThreshold < proportionChanged)
		changes = changes + 1;
		cutArray(changes) = count;
	end
end

cuts = cutArray;

end



% =========================================================================
% Overlay text
% =========================================================================
% Overlays text on the video indicating a scene cut has ocurred based on
% the frame indices generated by detectSceneCuts. After each cut, 30 frames
% have text placed on them, allowing enough time to read.
function final = overlayText(corrected, cuts)

final = corrected;

for count = 1 : length(cuts)
    frameBeforeCut = cuts(count);
    for frameIndex = 1 : 30
        frameWithText = insertText(final(:, :, frameBeforeCut + frameIndex), [40 300], ['SCENE CUT OCURRED']);
        final(:, :, frameBeforeCut + frameIndex) = frameWithText(:, :, 1);
    end
end

end



% =========================================================================
% Correction of global flicker
% =========================================================================
% Compare each frame with previous and find average intensity difference
% between them. Adjust each pixel of the first frame by this difference.
% The parameter 'frames' is just the frames in matrix format.
function corrected = correctGlobalFlicker(edited, initial, final, vertical, horizontal, numberOfFrames)
    
    corrected = edited;
    
    for count = initial + 1 : final

        firstFrame = edited(:, :, count - 1);
        secondFrame = edited(:, :, count);

        % Average pixel intensity and compute difference, mean2 for matrices
        intensityDifference = mean2(secondFrame) - mean2(firstFrame);

        for i = 1 : vertical
            for j = 1 : horizontal
                firstFrame(i, j) = firstFrame(i, j) + intensityDifference;
            end
        end 

        % Update state
        corrected(:, :, numberOfFrames) = firstFrame;

    end
end



% =========================================================================
% Correction of blotches
% =========================================================================
% Compute absolute difference between frames and generate movement mask by
% computing neighbourhood and summing absolute frame differences in those
% sections. Mark pixels with a great enough intensity disparity (based on
% threshold) as blotches, then unmark those covered by the movement mask to
% prevent false positives being treated as blotches. Readjust for noise and
% dilate mask to cover arefacts. Finally, overwrite blotches with mean of
% preceding two and following two frames.
function corrected = fixBlotches(edited, initial, final, blotchLimit)
    
    corrected = edited;
    % Play with this for different results
    blotchThreshold = 0.1;    
    thresholdNumber = 32;
    
    % Compute absolute frame difference
    absoluteFrameDifference = zeros(size(edited));
    for count = initial : final - 1
        precedingFrame = edited(:, :, count);
        followingFrame = edited(:, :, count + 1);
        frameDifference = abs(precedingFrame - followingFrame);
        absoluteFrameDifference(:, :, count) = frameDifference;
    end
    
    % Compute movement mask
    movementMask = zeros(size(edited));
    % Compute neighbourhood
    for count = initial : final
        % Round because discrete
        lowest = count - round(0.5 * thresholdNumber);
        highest = lowest + thresholdNumber;
        if (lowest < initial)
            lowest = initial;
            highest = initial + thresholdNumber;
        elseif (highest > final)
            lowest = final - thresholdNumber;
            highest = final;
        end
        differenceInNeighbourhood = absoluteFrameDifference(:, :, lowest : highest - 1);
        movementMask(:, :, count) = sum(differenceInNeighbourhood, 3);
    end
    % Mean filter mask (note medfilt doesn't give good results)
    movementMask = imfilter(movementMask, fspecial('average', 60));
    % Readjust for noise
    for count = 1 : numel(movementMask)
        if movementMask(count) >= blotchLimit
            movementMask(count) = 1;
        else
            movementMask(count) = 0;
        end
    end
    
    % Play with this for different results
    structuringElement = strel('square', 40);
    movementMask = imdilate(movementMask, structuringElement);
    notMoving = 1 - movementMask;
    
    % If greater than blotchThreshold, mark pixel as in a blotch
    pixelInBlotch = zeros(size(absoluteFrameDifference));
    for count = 1 : numel(absoluteFrameDifference)
        if absoluteFrameDifference(count) > blotchThreshold
            pixelInBlotch(count) = absoluteFrameDifference(count);
        end
    end
    
    % Unmark moving objects
    trueBlotch = times(pixelInBlotch, notMoving);
    
    % Make result in to bitmap
    for count = 1 : numel(trueBlotch)
        if trueBlotch(count) > 0
            trueBlotch(count) = 1;
        end
    end
    
    falseBlotch = 1 - trueBlotch;
    
    % Overwrite blotches with mean of preceding two frames and following
    % two frames. This is done two at a time to prevent the intensity cap
    % from having too significant an effect.
    for count = initial + 2 : final - 2
        meanOfPrecedingFrames = 0.5 * imadd(corrected(:, :, count - 2), corrected(:, :, count - 1));
        meanOfFollowingFrames = 0.5 * imadd(corrected(:, :, count + 1), corrected(:, :, count + 2));
        meanOfSurroundingFrames = 0.5 * imadd(meanOfPrecedingFrames, meanOfFollowingFrames);
        corrected(:, :, count) = times(meanOfSurroundingFrames, trueBlotch(:, :, count));
        corrected(:, :, count) = corrected(:, :, count) + times(edited(:, :, count), falseBlotch(:, :, count));
    end
end



% =========================================================================
% Correction of vertical artefacts
% =========================================================================
% For each frame in the range (note that this function is applied to the
% final scene only), loop through each row of pixels and apply a
% one-dimensional median filter to the corresponding intensity curve to
% smooth it but preserve edges. Resharpen the result with a Laplacian
% filter and readjust pixel intensity afterwards.
function corrected = correctVerticalArtefacts(edited, initial, final, vertical)

corrected = edited;

% Play with this for different results
filteringFactor = 5;

for count = initial : final
    for i = 1 : vertical
        corrected(i, :, count) = medfilt1(corrected(i, :, count), filteringFactor);
    end
    laplacianFilter = [0, 0, 0; 0, 1.2, 0; 0, 0, 0];
    corrected(:, :, count) = conv2(corrected(:, :, count), laplacianFilter, 'same');
    corrected(:, :, count) = 0.75 * corrected(:, :, count);
end

end



% =========================================================================
% Correction of camera shake
% =========================================================================
% Point feature matching video stabilisation. In each frame, salient points
% are collected using corner detection. Mappings between these points are
% computed using fast retina keypoint descriptors, which are binary so 
% Hamming distance can serve as a simple way to calculate matching cost.
% The distortion between frames is approximated through MATLAB's RANSAC
% variant function, with the affine transform represented by a
% scale-rotation-translation matrix. The video stabilisation algorithm used
% in this function is based on two separate papers which are cited in the
% attached report.
function corrected = correctCameraShake(edited, initial, final, vertical, horizontal)

corrected = edited;

% Play with this for different results
shakeThreshold = 0.05;

for count = initial + 1 : final
    
    firstFrameIndex = count;
    secondFrameIndex = count - 1;
    if (count >= final)
        firstFrameIndex = firstFrameIndex - 2;
    end
    
    firstFrame = edited(:, :, firstFrameIndex);
    secondFrame = edited(:, :, secondFrameIndex);
    
    baseFrame = edited(:, :, initial + 1);
    
    firstFramePoints = detectFASTFeatures(firstFrame, 'MinContrast', shakeThreshold);
    secondFramePoints = detectFASTFeatures(secondFrame, 'MinContrast', shakeThreshold);
    baseFramePoints = detectFASTFeatures(baseFrame, 'MinContrast', shakeThreshold);
    
    [firstFrameFeatures, firstFramePoints] = extractFeatures(firstFrame, firstFramePoints);
    [secondFrameFeatures, secondFramePoints] = extractFeatures(secondFrame, secondFramePoints);
    [baseFrameFeatures, baseFramePoints] = extractFeatures(baseFrame, baseFramePoints);
    [baseToFirstFrameFeatures, baseToFirstFrame] = extractFeatures(firstFrame, firstFramePoints);

    hammingDistancePairs = matchFeatures(secondFrameFeatures, firstFrameFeatures);
    hammingDistancePoints = matchFeatures(baseFrameFeatures, baseToFirstFrameFeatures);
    
    firstFramePoints = firstFramePoints(hammingDistancePairs(:, 2), :);
    secondFramePoints = secondFramePoints(hammingDistancePairs(:, 1), :);
    baseFramePoints = baseFramePoints(hammingDistancePoints(:, 1), :);
    baseToFirstFrame = baseToFirstFrame(hammingDistancePoints(:, 2), :);
    
    % Check if transform is possible based on lack of movement, three
    % points are required to match between frames
    [~, ~, ~, cannotTransform] = estimateGeometricTransform(baseToFirstFrame, baseFramePoints, 'affine');
    
    % If transform is possible, compute and apply
    if(cannotTransform == 0)
        
        [affineTransform, ~, ~] = estimateGeometricTransform(firstFramePoints, secondFramePoints, 'affine');
        
        baseComponent = affineTransform.T;
        rotationComponent = baseComponent(1 : 2, 1 : 2);
        rotationSection = rotationComponent([1 4]);
        
        % Note that there are two possible angles, therefore we take the
        % mean of these
        firstPossibleAngle = atan2(rotationComponent(2), rotationComponent(1));
        secondPossibleAngle = atan2(-rotationComponent(3), rotationComponent(4));
        averageAngle = mean([firstPossibleAngle secondPossibleAngle]);
        
        transformationScale = mean(rotationSection / cos(averageAngle));
        translation = baseComponent(3, 1 : 2);
        
        % Consolidate scaling, rotation and translation into final
        % composite transform
        finalTransform = [ [transformationScale * [cos(averageAngle) -sin(averageAngle); sin(averageAngle) cos(averageAngle)]; ...
          translation], [0 0 1]' ];
        twoDimensionalTransform = affine2d(finalTransform);

        stabilisedFrame = imwarp(firstFrame, twoDimensionalTransform, 'OutputView', imref2d(size(firstFrame)));
        newVertical = size(stabilisedFrame, 1);
        newHorizontal = size(stabilisedFrame, 2);
        
        % Note pixel crop size is 10
        corrected(:, :, secondFrameIndex) = imresize(stabilisedFrame(10 : newVertical - 10, 10 : newHorizontal - 10), [newVertical, newHorizontal]);
        
    % If affine transform not possible, just match position
    else
        
        % Again, pixel crop size is 10
        corrected(:, :, secondFrameIndex) = imresize(edited(10 : vertical - 10, 10 : horizontal - 10, secondFrameIndex), [vertical, horizontal]);
        
    end
    
end

end



% =========================================================================
% Apply corrections
% =========================================================================
% Function for applying different corrections to each scene in the
% appropriate way and order. Note, for example, that the noise threshold
% for blotches changes based on the scene/input type.
function corrected = applyCorrections(edited, cuts, first, last, vertical, horizontal, numberOfFrames)

corrected = edited;

% Play with this for different results (note scaling on middle scene for
% improved accuracy)
blotchLimit = 1;

% Input type 1: entire video
if (first == 1 && last == 657)
    
    firstTransition = cuts(1);
    secondTransition = cuts(2);
    
    % Initial scene
    corrected = correctGlobalFlicker(corrected, 1, firstTransition, vertical, horizontal, numberOfFrames);
    corrected = fixBlotches(corrected, 1, firstTransition, blotchLimit);
    corrected = correctCameraShake(corrected, 1, firstTransition, vertical, horizontal);
    
    % Middle scene
    corrected = correctGlobalFlicker(corrected, firstTransition + 1, secondTransition, vertical, horizontal, numberOfFrames);
    corrected = fixBlotches(corrected, firstTransition + 1, secondTransition, 0.365 * blotchLimit);
    corrected = correctCameraShake(corrected, firstTransition + 1, secondTransition, vertical, horizontal);
    
    % Last scene
    corrected = correctGlobalFlicker(corrected, secondTransition + 1, numberOfFrames, vertical, horizontal, numberOfFrames);
    corrected = correctVerticalArtefacts(corrected, secondTransition + 1, numberOfFrames, vertical);
    corrected = correctCameraShake(corrected, secondTransition + 1, numberOfFrames, vertical, horizontal);
    
% Input type 2: single frame
else 
    
    corrected = correctGlobalFlicker(corrected, 1, numberOfFrames, vertical, horizontal, numberOfFrames);
    corrected = fixBlotches(corrected, 1, numberOfFrames, blotchLimit);
    corrected = correctCameraShake(corrected, 1, numberOfFrames, vertical, horizontal);
 
end

end